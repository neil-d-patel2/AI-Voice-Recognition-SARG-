# SARG - Speech-Automated Real-time Game Tracker

A voice-activated baseball scorekeeping system that uses speech recognition and natural language processing to track game state in real-time.

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Features](#features)
- [Architecture](#architecture)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [How It Works](#how-it-works)
- [Testing](#testing)
- [Future Work](#future-work)
- [Contributors](#contributors)

## ğŸ¯ Overview

SARG (Speech-Automated Real-time Game tracker) is an automated baseball scorekeeping system that processes voice announcements and maintains accurate game state. The system uses OpenAI's Whisper for speech-to-text transcription and a local LLM (llama3.1) for structured play parsing.

### Key Capabilities
- **Voice-activated**: Processes audio announcements of baseball plays
- **Real-time tracking**: Updates game state including score, outs, count, and base runners
- **Intelligent parsing**: Uses LLM to extract structured play data from natural language
- **Visual interface**: PyQt5 GUI displays live game state
- **Undo functionality**: Can revert plays and replay game history
- **Persistent storage**: Saves/loads game state to/from JSON

## âœ¨ Features

### Core Functionality
- âœ… Tracks balls, strikes, outs, runs, and base runners
- âœ… Handles all play types: hits, outs, walks, strikeouts, double plays
- âœ… Manages inning progression (top/bottom transitions)
- âœ… Processes sacrifice flies with proper run scoring
- âœ… Supports complex scenarios (bases loaded, force plays, etc.)

### Advanced Features
- âœ… Voice command recognition ("undo" to revert last play)
- âœ… Transcript standardization for consistent parsing
- âœ… Game state context passed to LLM for accurate parsing
- âœ… Play-by-play history tracking
- âœ… GUI with live updates and undo button
- âœ… JSON persistence for game save/load

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Audio Input â”‚ (play1.mp3, play2.mp3, ...)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Speech Module   â”‚ (Whisper transcription)
â”‚ - transcribe    â”‚
â”‚ - clean         â”‚
â”‚ - standardize   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parser Module   â”‚ (LLM-based structured extraction)
â”‚ - LangChain     â”‚
â”‚ - Ollama/llama  â”‚
â”‚ - Pydantic      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GameState       â”‚ (Core game logic)
â”‚ - Play objects  â”‚
â”‚ - State machine â”‚
â”‚ - History       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GUI (PyQt5)     â”‚ (Visual display)
â”‚ - Live updates  â”‚
â”‚ - Undo button   â”‚
â”‚ - History view  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Installation

### Prerequisites
- Python 3.9+
- ffmpeg (for audio processing)
- Ollama with llama3.1 model

### Step 1: Install Dependencies

```bash
# Clone the repository
cd SARG-project

# Install Python packages
pip install -r requirements.txt
```

### Step 2: Install Ollama and Model

```bash
# Install Ollama (macOS)
brew install ollama

# Start Ollama service
ollama serve

# Pull llama3.1 model
ollama pull llama3.1
```

### Step 3: Install ffmpeg

```bash
# macOS
brew install ffmpeg

# Linux
sudo apt-get install ffmpeg

# Windows
# Download from https://ffmpeg.org/download.html
```

## ğŸ’» Usage

### Basic Usage

1. **Prepare audio files**: Record play-by-play announcements following the standardized format (see [Announcement Format](#announcement-format))

2. **Update main.py**: Set your audio file list
```python
play_files = ["play1.mp3", "play2.mp3", "play3.mp3"]
```

3. **Run the program**:
```bash
python3 main.py
```

4. **View results**: The GUI will display the game state after each play

### Announcement Format

Follow this format for consistent parsing:

```
[Batter Name] [Action]. Count: [Balls]-[Strikes]. [Base State]. [Outs]. [Score].
```

**Examples:**
```
Marcus takes a ball. Count: 1-0. Bases empty. No outs. Score: 0-0.

Jessica hits a home run. Count: 0-0. Bases empty. No outs. Score: 2-0.

Chen grounds out to shortstop. Count: 0-0. Bases empty. 1 out. Score: 2-0.
```

### Voice Commands

- Say **"undo"** in an audio file to undo the last play
- GUI undo button also available

## ğŸ“ Project Structure

```
SARG-project/
â”œâ”€â”€ main.py              # Main entry point, orchestrates components
â”œâ”€â”€ gamestate.py         # Core game state management and logic
â”œâ”€â”€ schema.py            # Pydantic models for Play and RunnerMovement
â”œâ”€â”€ parse_play.py        # LLM-based play parsing with prompt
â”œâ”€â”€ speech.py            # Whisper transcription and cleaning
â”œâ”€â”€ userinterf.py        # PyQt5 GUI interface
â”œâ”€â”€ recorder.py          # Audio recording utilities (optional)
â”œâ”€â”€ README.md            # This file
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ audio/              
    â”œâ”€â”€ play1.mp3        # Test audio files
    â”œâ”€â”€ play2.mp3
    â””â”€â”€ ...
```

## ğŸ”§ How It Works

### 1. Audio Transcription (`speech.py`)
- **Whisper** converts audio to text
- **Clean**: Fixes common transcription errors (e.g., "basis" â†’ "bases")
- **Standardize**: Formats transcript to match expected pattern

### 2. Play Parsing (`parse_play.py`)
- **LangChain** + **Ollama** extract structured data
- Prompt includes:
  - Current game state context (who's on base, count, outs)
  - Play type identification rules
  - 9+ concrete examples for pattern matching
- **Pydantic** validates output structure

### 3. Game State Update (`gamestate.py`)
- Validates play against current state
- Applies runner movements
- Updates count, outs, score
- Handles special cases (sac fly, double play, inning change)
- Stores play in history for undo/replay

### 4. GUI Display (`userinterf.py`)
- Shows live game state
- Displays last 3 plays
- Provides undo button with confirmation
- Updates automatically after each play

## ğŸ§ª Testing

### Test Play Sequences

Run the included test sequences:

```python
# 12-play test (complete half-inning)
play_files = ["test_play1.mp3", ..., "test_play12.mp3"]

# Double play tests
play_files = ["dp_setup.mp3", "dp_play.mp3"]
```

### Jupyter Notebook Testing

See `double_play_test.ipynb` for interactive testing:

```python
from gamestate import GameState
from parse_play import parse_transcript

# Test individual plays
game = GameState("HOME", "AWAY")
play = parse_transcript("Marcus hits a single. Count: 0-0...")
game.update(play)
print(game)
```

### Expected Outputs

After 12 test plays, final state should be:
```
AWAY: 3 | HOME: 0 | Inning: Bottom 1, Count: 0-0, Outs: 0 | Bases empty
```

## ğŸ› Known Issues & Limitations

1. **LLM Accuracy**: Local llama3.1 model occasionally misparses complex plays
2. **Audio Quality**: Whisper transcription quality depends on clear audio
3. **Manual Transcripts**: System requires pre-recorded audio files (no live recording yet)
4. **Double Plays**: Complex runner movements sometimes need manual correction
5. **No Replay Analysis**: Can't easily visualize play history

## ğŸš€ Future Work

### Short-term Improvements
- [ ] Add live audio recording mode
- [ ] Implement GPT-4 mini for better parsing accuracy
- [ ] Add pitch-level tracking (velocity, location)
- [ ] Support for pinch hitters and substitutions

### Long-term Goals
- [ ] Real-time game streaming integration
- [ ] Database storage (PostgreSQL) instead of JSON
- [ ] Web dashboard for remote viewing
- [ ] Statistical analysis and reports
- [ ] Mobile app version
- [ ] Support for other sports (basketball, football)

## ğŸ“Š Performance

- **Transcription**: ~2-5 seconds per play (Whisper base model)
- **Parsing**: ~1-3 seconds per play (llama3.1)
- **State Update**: <0.1 seconds
- **Total**: ~3-8 seconds per play

## ğŸ¤ Contributors

- **Your Name** - Initial development, core architecture
- **Course**: [Course Name/Number]
- **Institution**: [University Name]
- **Semester**: Fall 2024

## ğŸ“ License

This project is licensed for educational purposes.

## ğŸ™ Acknowledgments

- OpenAI Whisper for speech recognition
- Ollama team for local LLM deployment
- LangChain for LLM orchestration
- PyQt5 for GUI framework

## ğŸ“ Contact

For questions or issues, contact: [your-email@example.com]

---

**Note**: This is an academic project demonstrating the integration of speech recognition, natural language processing, and game state management. It is not intended for production use without significant additional testing and refinement.
